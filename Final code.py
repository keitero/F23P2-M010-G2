import random

c_avg = [7, 4, 10, 5]
c_dev = [3,10,6,2]

def exploreOnly() -> float:
    c1_hap = 0
    c2_hap = 0
    c3_hap = 0
    c4_hap = 0
    # getting sum of happiness for C1
    for i in range(50):
        a = random.normalvariate(c_avg[0], c_dev[0])
        c1_hap += a
    # getting sum of happiness for C2
    for i in range(50):
        a = random.normalvariate(c_avg[1], c_dev[1])
        c2_hap += a
    # getting sum of happiness for C3
    for i in range(50):
        a = random.normalvariate(c_avg[2], c_dev[2])
        c3_hap += a
    # getting sum of happiness for C4
    for i in range(50):
        a = random.normalvariate(c_avg[3], c_dev[3])
        c4_hap += a
    # formats the code and turns the string into float
    return float(format(c1_hap + c2_hap + c3_hap + c4_hap, ".2f"))

def exploitOnly():
    total_happiness = 0

    # Simulate visiting each cafeteria for the first four days
    happiness_cafeteria_1 = random.normalvariate(c_avg[0], c_dev[0])  # Cafeteria 1
    happiness_cafeteria_2 = random.normalvariate(c_avg[1], c_dev[1])    # Cafeteria 2
    happiness_cafeteria_3 = random.normalvariate(c_avg[2], c_dev[2])  # Cafeteria 3
    happiness_cafeteria_4 = random.normalvariate(c_avg[3], c_dev[3])  # Cafeteria 4

    happiness_values = [happiness_cafeteria_1, happiness_cafeteria_2, happiness_cafeteria_3, happiness_cafeteria_4]

    # Find the best cafeteria based on the highest happiness value
    best_cafeteria = happiness_values.index(max(happiness_values))

    # Visit the best cafeteria for the next 196 days and calculate happiness
    for i in range(196):
        if best_cafeteria == 0:
            c_avgb = c_avg[0]
            c_devb = c_dev[0]
        elif best_cafeteria == 1:
            c_avgb = c_avg[1]
            c_devb = c_dev[1]
        elif best_cafeteria == 2:
            c_avgb = c_avg[2]
            c_devb = c_dev[2]
        else:
            c_avgb = c_avg[3]
            c_devb = c_dev[3]

        happiness = random.normalvariate(c_avgb, c_devb)
        total_happiness = total_happiness + happiness

    # Add the happiness values of the first four days
    total_happiness += sum(happiness_values)

    return total_happiness

def eGreedy(e = 10) -> float:# take e as input, default e as 10
    LC1 = []
    LC2 = []
    LC3 = []
    LC4 = []# set four lists to record all the happiness generated by each cafe

    # first 4 days, visit each cafe once
    VC1 = random.normalvariate(c_avg[0], c_dev[0])  # use Normal Distribution to get a random value
    LC1.append(VC1) # add the happiness value into the list
    AC1 = sum(LC1)/len(LC1) # get the current average happiness value for each cafe

    VC2 = random.normalvariate(c_avg[1], c_dev[1])
    LC2.append(VC2)
    AC2 = sum(LC2) / len(LC2)

    VC3 = random.normalvariate(c_avg[2], c_dev[2])
    LC3.append(VC3)
    AC3 = sum(LC3) / len(LC3)

    VC4 = random.normalvariate(c_avg[3], c_dev[3])
    LC4.append(VC4)
    AC4 = sum(LC4) / len(LC4)
    # repeat the step for each cafe once, 196 days left

    # eGreedy requires me to track the highest average value.
    current_highest_average = max(AC1,AC2,AC3,AC4) # find the highest average for the first 4 days
    LA = [AC1,AC2,AC3,AC4] # make all the average into a list which will be used later

    # for the 196 days left, we will use eGreedy
    for i in range(196): # 196 days left, so it should run 196 times
        r = random.random() # get a random r value
        if r < e/100: # when r is smaller than e%, we let it go to random cafe
            i = random.randint(1,4) # get a random cafe number
            if i == 1: # according to the random cafe number, we go to the cafe
                VC1 = random.normalvariate(c_avg[0], c_dev[0])
                LC1.append(VC1)
                AC1 = sum(LC1) / len(LC1) # the same as above, happiness and current average for the cafe
            elif i == 2:
                VC2 = random.normalvariate(c_avg[1], c_dev[1])
                LC2.append(VC2)
                AC2 = sum(LC2)/len(LC2)
            elif i == 3:
                VC3 = random.normalvariate(c_avg[2], c_dev[2])
                LC3.append(VC3)
                AC3 = sum(LC3)/len(LC3)
            else:
                VC4 = random.normalvariate(c_avg[3], c_dev[3])
                LC4.append(VC4)
                AC4 = sum(LC4)/len(LC4)
            current_highest_average = max(AC1, AC2, AC3, AC4) # get the highest after each visit
            LA = [AC1, AC2, AC3, AC4]# make the new average into list

        else: # when r is bigger than e%, we will go to the cafe that has the highest average value
            i = LA.index(max(LA)) # find which cafe has the highest avg happiness now
            if i == 0: # then go to the cafe
                VC1 = random.normalvariate(c_avg[0], c_dev[0])
                LC1.append(VC1)
                AC1 = sum(LC1) / len(LC1) # same way as each visit
            elif i == 1:
                VC2 = random.normalvariate(c_avg[1], c_dev[1])
                LC2.append(VC2)
                AC2 = sum(LC2) / len(LC2)
            elif i == 2:
                VC3 = random.normalvariate(c_avg[2], c_dev[2])
                LC3.append(VC3)
                AC3 = sum(LC3) / len(LC3)
            else:
                VC4 = random.normalvariate(c_avg[3], c_dev[3])
                LC4.append(VC4)
                AC4 = sum(LC4) / len(LC4)
            current_highest_average = max(AC1, AC2, AC3, AC4) # also get the current highest after visit
            LA = [AC1, AC2, AC3, AC4] # make new avg into list

    # when the loop is done, we can get total happiness
    total_happiness = sum(LC1) + sum(LC2) + sum(LC3) + sum(LC4) # get the total happiness by adding all the sum value of the lists
    return  total_happiness # return the result

def simulation(t: int, e=10) -> None:
    # creation of all the local variables used in the function
    days = 200

    # storage of simulated values
    exploit_vals = []
    explore_vals = []
    greed_vals = []

    # optimum happiness calculation
    opt_hap = max(c_avg) * days

    # expected values
    # sorting the list from highest to lowest value
    l1 = sorted(c_avg, reverse=True)
    exploit_exp = 197 * l1[0] + l1[1] + l1[2] + l1[3]
    explore_exp = c_avg[0] * (days/4) + c_avg[1] * (days/4) + c_avg[2] * (days/4) + c_avg[3] * (days/4)
    # all my work to calculate greed_exp
    best_days = ((100-e)/100)*days
    sub_days = ((e/100)*days)/4
    greed_exp = l1[0] * best_days + l1[0] * sub_days + l1[1] * sub_days + l1[2] * sub_days + l1[3] * sub_days

    # setting the sim values
    exploit_sim = 0
    explore_sim = 0
    greed_sim = 0

    # doing the simulation t amount of times
    for i in range(0, t):
        # storing the values in the list each time
        exploit_vals.append(exploitOnly())
        explore_vals.append(exploreOnly())
        greed_vals.append(eGreedy(e))

    # get simulated happiness for exploreOnly() by finding the average
    for i in explore_vals:
        explore_sim += i
    # avg value
    explore_sim = explore_sim / t

    # get simulated happiness for exploitOnly() by finding the average
    for i in exploit_vals:
        exploit_sim += i
    # avg value
    exploit_sim = exploit_sim / t

    # get simulated happiness for eGreed() by finding the average
    for i in greed_vals:
        greed_sim += i
    # avg value
    greed_sim = greed_sim / t

    # getting regret values by subtracting from optimal happiness
    expReg_explore = format(opt_hap - explore_exp, ".2f")
    expReg_exploit = format(opt_hap - exploit_exp, ".2f")
    expReg_greed = format(opt_hap - greed_exp, ".2f")
    simReg_explore = format(opt_hap - explore_sim, ".2f")
    simReg_exploit = format(opt_hap - exploit_sim, ".2f")
    simReg_greed = format(opt_hap - greed_sim, ".2f")

    # turning the regrets into a string
    exploit_exp = format(exploit_exp, ".2f")
    explore_exp = format(explore_exp, ".2f")
    greed_exp = format(greed_exp, ".2f")

    # turning sims to string
    explore_sim = format(explore_sim, ".2f")
    exploit_sim = format(exploit_sim, ".2f")
    greed_sim = format(greed_sim, ".2f")

    # turning opt happiness into a string
    opt_hap = format(opt_hap, ".2f")

    # big print statement

    print("Optimum Happiness: " + opt_hap + "\n" +
          # this is the explore stuff
          "\nExplore Only:\nExpected Happiness: " + explore_exp +
          "\nExpected Regret: " + expReg_explore +
          "\nSimulated Happiness: " + explore_sim + "\nSimulated Regret: " +
          simReg_explore + "\n" +
          # this is the exploit stuff
          "\nExploit Only:\nExpected Happiness: " + exploit_exp +
          "\nExpected Regret: " + expReg_exploit +
          "\nSimulated Happiness: " + exploit_sim + "\nSimulated Regret: " +
          simReg_exploit + "\n" +
          # this is the greed stuff
          "\neGreedy:\nExpected Happiness: " + greed_exp +
          "\nExpected Regret: " + expReg_greed +
          "\nSimulated Happiness: " + greed_sim + "\nSimulated Regret: " +
          simReg_greed)


simulation(10)
